\relax 
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Simulation Results}}{1}}
\newlabel{fig_sim}{{1}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {I-A}}Objectifs}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Mod\IeC {\'e}lisation d\IeC {\textquoteright }un neurone}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Mod\IeC {\`e}le de perceptron utilise dans le r\IeC {\'e}seau de neurones}}{1}}
\newlabel{fig:perceptron_modelo}{{2}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-A}}Le perceptron : fonctions de transition classiques}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Fonction sigmoide et sa deriv\IeC {\'e}}}{2}}
\newlabel{fig:sigmoide}{{3}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-B}}Le perceptron : r\IeC {\^o}le de l\IeC {\textquoteright }unit\IeC {\'e} de biais}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Le perceptron multicouche}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}Architecture utilise}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Architecture de la r\IeC {\'e}seaux utilis\IeC {\'e}. MLP conventional }}{2}}
\newlabel{fig:ArchitectureMLP}{{4}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}L\IeC {\textquoteright }erreur du perceptron : une fonction multidimensionelle}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Courbes indicant l'erreur d'apprentissage (risque empirique) et l'erreur de test(risque r\IeC {\'e}el)}}{2}}
\newlabel{fig:courbesError}{{5}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}L\IeC {\textquoteright }apprentissage supervis\IeC {\'e}}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Algorithme BackPropagation : calcul du vecteur gradient}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Cas d\IeC {\textquoteright }un perceptron multicouche : implementations}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-A}}Base d'apprentissage et de test}{3}}
\newlabel{code_initial}{{1}{3}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {1}Code puor initialisation des variables}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Comparation entre les attributs normalis\IeC {\'e}es,non normalis\IeC {\'e}s}}{3}}
\newlabel{fig:AttributsNorm}{{6}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-B}}Parametrage du MLP}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Histogramme des poids de la couche de sortie }}{3}}
\newlabel{fig:histoW}{{7}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-C}}Test sur une version simple du MLP}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Histogramme des poids de la couche de cach\IeC {\'e}e}}{4}}
\newlabel{fig:histoC}{{8}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Graphique pour comparation des poids de sortie initiaux et finales}}{4}}
\newlabel{fig:SignauxNormalises}{{9}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces R\IeC {\'e}sultats de implementation simple MLP, $\mu =0.5$,initialisation poids non normalement distribu\IeC {\'e}e}}{4}}
\newlabel{fig:CourbeError}{{10}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {VII}Amelioration de l'algorithme pour une meuilleur convergence}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {VIII}Programme rs2 : initialisation des poids avec distribution normal}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Histogramme des poids de la couche de entr\IeC {\'e}e d'une neurone.Distribution Normal }}{4}}
\newlabel{fig:histoW}{{11}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Histogramme des poids de la couche de sortie d'une neurone.Distribution Normal }}{5}}
\newlabel{fig:histoW}{{12}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {IX}Programme rs3 : On rajoute un taux d'apprentissage variable}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Simulation Results}}{5}}
\newlabel{fig_sim}{{13}{5}}
\bibcite{IEEEhowto:kopka}{1}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Simulation Results}}{6}}
\newlabel{fig_sim}{{14}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Simulation Results}}{6}}
\newlabel{fig_sim}{{15}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {X}Programme Rs4 : On rajoute deux taux d'apprentissage variable}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Simulation Results}}{6}}
\newlabel{fig_sim}{{16}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {XI}Conclusion}{6}}
\@writefile{toc}{\contentsline {section}{Appendix\nobreakspace  {}A: Proof of the First Zonklar Equation}{6}}
\@writefile{toc}{\contentsline {section}{References}{7}}
